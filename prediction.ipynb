{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries for prediciton\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_matrix(matrix, row_label, col_label):\n",
    "    \"\"\"Pretty print of the given matrix \"\"\"\n",
    "\n",
    "    # Restraining labels that are too big\n",
    "    row_label = [el[:10] + '..' if len(el) > 10 else el\n",
    "                for el in row_label]\n",
    "    col_label = [el[:10] + '..' if len(el) > 10 else el\n",
    "                for el in col_label]\n",
    "\n",
    "    # Stringfying everything & Joining top label\n",
    "    s_matrix = [list([\" \"] + (col_label))] + \\\n",
    "               [[row_label[row_idx]] + \\\n",
    "                [str(e) for e in row] for row_idx, row in enumerate(matrix)]\n",
    "\n",
    "    # Length of each matrix column\n",
    "    len_s = [max(map(len, col)) for col in zip(*s_matrix)]\n",
    "\n",
    "    # Cell formatation\n",
    "    formatation = '\\t'.join('{{:{}}}'.format(x) for x in len_s)\n",
    "\n",
    "    # Apply cell formation to each matrix element\n",
    "    pretty_mat = [formatation.format(*row) for row in s_matrix]\n",
    "\n",
    "    # Print Pretty Matrix\n",
    "    print('\\n'.join(pretty_mat))\n",
    "\n",
    "\n",
    "def display_confusion_matrix(values):\n",
    "    '''Display the given array as a confusion matrix'''\n",
    "    pretty_matrix([values[0:2], values[2:4]],\n",
    "                  ['Actual NO', 'Actual YES'],\n",
    "                  ['Predic NO', 'Predic YES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Algorithms\n",
    "\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DT():\n",
    "    '''Create a new Decision Tree'''\n",
    "    # Useful DecisionTree tutorial:\n",
    "    # https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "    return DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RF():\n",
    "    '''Create a new Ranfom Forest model'''\n",
    "    return RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient Boosting - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_XGB():\n",
    "    '''Create a Gradient Boost Model'''\n",
    "    return XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>frequency_MI</th>\n",
       "      <th>frequency_WI</th>\n",
       "      <th>balance_mean</th>\n",
       "      <th>balance_max</th>\n",
       "      <th>balance_min</th>\n",
       "      <th>...</th>\n",
       "      <th>no. of enterpreneurs per 1000 inhabitants</th>\n",
       "      <th>no. of commited crimes '95</th>\n",
       "      <th>no. of commited crimes '96</th>\n",
       "      <th>owner_count</th>\n",
       "      <th>disponent_count</th>\n",
       "      <th>owner_gender</th>\n",
       "      <th>owner_birthdate</th>\n",
       "      <th>loan_to_account_age</th>\n",
       "      <th>salary_over_payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>96396</td>\n",
       "      <td>12</td>\n",
       "      <td>8033</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12250.000000</td>\n",
       "      <td>20100.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>2985</td>\n",
       "      <td>2804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272076</td>\n",
       "      <td>105</td>\n",
       "      <td>1617</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262785</td>\n",
       "      <td>52128</td>\n",
       "      <td>24</td>\n",
       "      <td>2172</td>\n",
       "      <td>0.193010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33459.680282</td>\n",
       "      <td>59944.2</td>\n",
       "      <td>144.2</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>2985</td>\n",
       "      <td>2804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533465</td>\n",
       "      <td>264</td>\n",
       "      <td>7478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004721</td>\n",
       "      <td>165960</td>\n",
       "      <td>36</td>\n",
       "      <td>4610</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52083.859459</td>\n",
       "      <td>120512.8</td>\n",
       "      <td>700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>2854</td>\n",
       "      <td>2618</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730073</td>\n",
       "      <td>148</td>\n",
       "      <td>3759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018096</td>\n",
       "      <td>127080</td>\n",
       "      <td>60</td>\n",
       "      <td>2118</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30060.954167</td>\n",
       "      <td>49590.4</td>\n",
       "      <td>800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>2080</td>\n",
       "      <td>2122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>170</td>\n",
       "      <td>6272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306845</td>\n",
       "      <td>74736</td>\n",
       "      <td>36</td>\n",
       "      <td>2076</td>\n",
       "      <td>0.130262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37912.998507</td>\n",
       "      <td>62084.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>2080</td>\n",
       "      <td>2122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670547</td>\n",
       "      <td>399</td>\n",
       "      <td>6314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  amount  duration  payments  account_creation_date  frequency_MI  \\\n",
       "0  0.000000   96396        12      8033               0.054011             0   \n",
       "1  0.262785   52128        24      2172               0.193010             1   \n",
       "2  0.004721  165960        36      4610               0.024623             1   \n",
       "3  0.018096  127080        60      2118               0.020651             1   \n",
       "4  0.306845   74736        36      2076               0.130262             1   \n",
       "\n",
       "   frequency_WI  balance_mean  balance_max  balance_min  ...  \\\n",
       "0             1  12250.000000      20100.0       1100.0  ...   \n",
       "1             0  33459.680282      59944.2        144.2  ...   \n",
       "2             0  52083.859459     120512.8        700.0  ...   \n",
       "3             0  30060.954167      49590.4        800.0  ...   \n",
       "4             0  37912.998507      62084.0        700.0  ...   \n",
       "\n",
       "   no. of enterpreneurs per 1000 inhabitants   no. of commited crimes '95   \\\n",
       "0                                         100                         2985   \n",
       "1                                         100                         2985   \n",
       "2                                         117                         2854   \n",
       "3                                         132                         2080   \n",
       "4                                         132                         2080   \n",
       "\n",
       "   no. of commited crimes '96   owner_count  disponent_count  owner_gender  \\\n",
       "0                         2804            1                1             1   \n",
       "1                         2804            1                1             1   \n",
       "2                         2618            1                1             0   \n",
       "3                         2122            1                1             0   \n",
       "4                         2122            1                1             0   \n",
       "\n",
       "   owner_birthdate  loan_to_account_age  salary_over_payments  status  \n",
       "0         0.272076                  105                  1617      -1  \n",
       "1         0.533465                  264                  7478       1  \n",
       "2         0.730073                  148                  3759       1  \n",
       "3         0.029255                  170                  6272       1  \n",
       "4         0.670547                  399                  6314       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'amount',\n",
       " 'duration',\n",
       " 'payments',\n",
       " 'account_creation_date',\n",
       " 'frequency_MI',\n",
       " 'frequency_WI',\n",
       " 'balance_mean',\n",
       " 'balance_max',\n",
       " 'balance_min',\n",
       " 'last_ballance',\n",
       " 'credit_mean',\n",
       " 'credit_count',\n",
       " 'credit_max',\n",
       " 'credit_min',\n",
       " 'withdrawal_mean',\n",
       " 'withdrawal_count',\n",
       " 'withdrawal_max',\n",
       " 'withdrawal_min',\n",
       " 'operation_CC',\n",
       " 'operation_CAB',\n",
       " 'operation_WC',\n",
       " 'operation_RAB',\n",
       " 'operation_CCW',\n",
       " 'mean_trans_profit',\n",
       " 'total_ops',\n",
       " 'total_trans',\n",
       " 'name ',\n",
       " 'region',\n",
       " 'no. of inhabitants',\n",
       " 'no. of municipalities with inhabitants less than 499',\n",
       " 'no. of municipalities with inhabitants 500-1999',\n",
       " 'no. of municipalities with inhabitants 2000-9999 ',\n",
       " 'no. of municipalities with inhabitants more than 10000',\n",
       " 'no. of cities ',\n",
       " 'ratio of urban inhabitants ',\n",
       " 'average salary ',\n",
       " \"unemploymant rate '95 \",\n",
       " \"unemploymant rate '96 \",\n",
       " 'no. of enterpreneurs per 1000 inhabitants ',\n",
       " \"no. of commited crimes '95 \",\n",
       " \"no. of commited crimes '96 \",\n",
       " 'owner_count',\n",
       " 'disponent_count',\n",
       " 'owner_gender',\n",
       " 'owner_birthdate',\n",
       " 'loan_to_account_age',\n",
       " 'salary_over_payments',\n",
       " 'status']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset =  utils.read_csv_to_df('dataset/preprocessed_data.csv')\n",
    "dataset.rename(columns={'no. of municipalities with inhabitants < 499 ': 'no. of municipalities with inhabitants less than 499',\n",
    "                         'no. of municipalities with inhabitants >10000 ': 'no. of municipalities with inhabitants more than 10000'}, \n",
    "                 inplace=True)\n",
    "display(dataset.head())\n",
    "list(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful MACROS\n",
    "STATUS_COL = dataset.columns.get_loc(\"status\")\n",
    "K_FOLD_NUM_SPLITS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and Y\n",
    "X = dataset.iloc[:, 0:STATUS_COL]\n",
    "y = dataset.iloc[:, [STATUS_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2936 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4344 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   48.9s finished\n",
      "E:\\Programas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=False),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=n...\n",
       "                                           verbosity=None),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0, 1.2,\n",
       "                                                             1.4],\n",
       "                                        'gamma': [0, 0.5, 1, 1.5, 2, 2.5, 5],\n",
       "                                        'learning_rate': [0.03, 0.01, 0.003,\n",
       "                                                          0.001],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                      12, 14],\n",
       "                                        'min_child_weight': [1, 3, 5, 7, 10],\n",
       "                                        'reg_lambda': array([0.4, 0.6, 0.8, 1. , 1.2, 1.4]),\n",
       "                                        'subsample': [0.6, 0.8, 1.0, 1.2, 1.4]},\n",
       "                   random_state=42, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyper Parameter Tuning for XGBOOST adapted from \"https://towardsdatascience.com/what-is-xgboost-and-how-to-optimize-it-d3c24e0e41b4\"\n",
    "#RANDOMIZED SEARCH\n",
    "#imports\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "xgb_pipeline =XGBClassifier()\n",
    "\n",
    "# set the parameters you want tune \n",
    "params = {\n",
    "        'learning_rate': [0.03, 0.01, 0.003, 0.001],\n",
    "        'min_child_weight': [1,3, 5,7, 10],\n",
    "        'gamma': [0, 0.5, 1, 1.5, 2, 2.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0, 1.2, 1.4],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0, 1.2, 1.4],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8, 9 ,10, 12, 14],\n",
    "        'reg_lambda':np.array([0.4, 0.6, 0.8, 1, 1.2, 1.4])}\n",
    "\n",
    "\n",
    "# let's run the optimization\n",
    "random_search = RandomizedSearchCV(xgb_pipeline, param_distributions=params, n_iter=1000,\n",
    "                                   scoring=\"roc_auc\", n_jobs=-1,  verbose=3, random_state=42, cv=KFold(n_splits=K_FOLD_NUM_SPLITS, random_state=SEED, shuffle=False))\n",
    "# n_iter : number of iteration\n",
    "# scoring : loss \n",
    "# n_jobs : parallel computation if -1 means use all the threads available\n",
    "# cv : number of folds of the cross-validation \n",
    "\n",
    "# fit the model on training data with specific parameters\n",
    "random_search.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=2.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.03, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=0.6, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1349s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 578 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 628 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 682 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 794 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 914 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1108 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1248 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1322 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1396 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1474 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1634 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1716 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1802 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1888 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1978 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2068 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2354 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2554 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2656 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2762 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2868 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2978 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3202 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3316 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3674 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3796 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3922 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4048 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4178 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4308 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4714 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4845 out of 4860 | elapsed:  2.1min remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4860 out of 4860 | elapsed:  2.1min finished\n",
      "E:\\Programas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=False),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, mon...\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': array([0.5, 0.6, 0.7]),\n",
       "                         'learning_rate': array([0.02, 0.03, 0.04]),\n",
       "                         'max_depth': array([4, 5, 6, 7]),\n",
       "                         'min_child_weight': array([0.9, 1. , 1.1]),\n",
       "                         'reg_lambda': array([0.5, 0.6, 0.7]),\n",
       "                         'subsample': array([0.7, 0.8, 0.9])},\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GRIDSEARCH\n",
    "    \n",
    "# param to be tested \n",
    "gbm_param_grid = {\n",
    "    'learning_rate': np.array(range(int(100*random_search.best_params_[\"learning_rate\"])-1, int(100*random_search.best_params_[\"learning_rate\"])+2, 1))/100,\n",
    "    'subsample': np.array(range(int(10*random_search.best_params_[\"subsample\"])-1, int(10*random_search.best_params_[\"subsample\"])+2, 1))/10,\n",
    "    'reg_lambda': np.array(range(int(10*random_search.best_params_[\"reg_lambda\"])-1, int(10*random_search.best_params_[\"reg_lambda\"])+2, 1))/10,\n",
    "    'max_depth':np.array(range(random_search.best_params_[\"max_depth\"]-1, random_search.best_params_[\"max_depth\"]+3, 1)),\n",
    "    'colsample_bytree': np.array(range(int(10*random_search.best_params_[\"colsample_bytree\"])-1, int(10*random_search.best_params_[\"colsample_bytree\"])+2, 1))/10,\n",
    "    'min_child_weight': np.array(range(int(10*random_search.best_params_[\"min_child_weight\"])-1, int(10*random_search.best_params_[\"min_child_weight\"])+2, 1))/10\n",
    "}\n",
    "#'gamma': np.array(range(int(10*random_search.best_params_[\"gamma\"])-3, int(10*random_search.best_params_[\"gamma\"])+3, 1))/10,\n",
    "\n",
    "\n",
    "# configure the gridsearch \n",
    "grid_search = GridSearchCV(estimator=xgb_pipeline, param_grid=gbm_param_grid, n_jobs=-1, cv=KFold(n_splits=K_FOLD_NUM_SPLITS, random_state=SEED, shuffle=False),\n",
    "                         scoring='roc_auc', verbose=10 )\n",
    "# n_jobs : number of thread in parallel if -1 means max thread used\n",
    "# cv : number of fold in cross-validation\n",
    "\n",
    "# train the models \n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.04, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1.1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=0.6, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation settings\n",
    "auc_scores = []\n",
    "confusion_matrixes = []\n",
    "cv = KFold(n_splits=K_FOLD_NUM_SPLITS, random_state=SEED, shuffle=False)\n",
    "\n",
    "# CHANGE THIS LINE TO CHANGE THE USED CLASSIFICATION METHOD\n",
    "# classifier = create_DT()\n",
    "# classifier = create_RF()\n",
    "classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.04, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1.1, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=0.6, scale_pos_weight=1, subsample=0.8,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Applying Cross validation\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Training with this fold\n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    # Testing & Measuring accuracy\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    auc_scores.append(metrics.auc(fpr, tpr))\n",
    "    confusion_matrixes.append(metrics.confusion_matrix(y_test, y_pred).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Method used: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.04, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1.1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=0.6, scale_pos_weight=1, subsample=0.8,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) \n",
      "\n",
      "AUC scores: [0.5909090909090908, 0.6788793103448276, 0.7, 0.8333333333333334, 0.6153846153846154]\n",
      "> Average:  0.6837012699943734\n",
      "          \tPredic NO\tPredic YES\n",
      "Actual NO \t2        \t9         \n",
      "Actual YES\t0        \t55        \n",
      "          \tPredic NO\tPredic YES\n",
      "Actual NO \t3        \t5         \n",
      "Actual YES\t1        \t57        \n",
      "          \tPredic NO\tPredic YES\n",
      "Actual NO \t2        \t3         \n",
      "Actual YES\t0        \t61        \n",
      "          \tPredic NO\tPredic YES\n",
      "Actual NO \t6        \t3         \n",
      "Actual YES\t0        \t56        \n",
      "          \tPredic NO\tPredic YES\n",
      "Actual NO \t3        \t10        \n",
      "Actual YES\t0        \t52        \n"
     ]
    }
   ],
   "source": [
    "# Printing the obtained results\n",
    "print('Classification Method used:', classifier, '\\n')\n",
    "print('AUC scores:', auc_scores)\n",
    "print('> Average: ', sum(auc_scores)/len(auc_scores))\n",
    "for cf in confusion_matrixes:\n",
    "    display_confusion_matrix(cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After having our model trained we shall use the model on the data to be sumitted in the kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =  utils.read_csv_to_df('dataset/test_dataset.csv')\n",
    "ids = utils.read_csv_to_df('dataset/ids.csv')\n",
    "display(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now remove the Y column with NaNs\n",
    "test_dataset = test_dataset.iloc[:, 0:STATUS_COL]\n",
    "display(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to get the 'status' predictions\n",
    "test_dataset.rename(columns={'no. of municipalities with inhabitants < 499 ': 'no. of municipalities with inhabitants less than 499',\n",
    "                         'no. of municipalities with inhabitants >10000 ': 'no. of municipalities with inhabitants more than 10000'}, \n",
    "                 inplace=True)\n",
    "display(test_dataset)\n",
    "predictions_df = test_dataset.copy()\n",
    "predictions_df['Predicted'] = classifier.predict(test_dataset)\n",
    "predictions_df = ids.merge(predictions_df, on=['date', 'amount'])\n",
    "predictions_df = predictions_df[['loan_id', 'Predicted']]\\\n",
    "                    .rename(columns={\n",
    "                        'loan_id': 'Id'\n",
    "                    })\\\n",
    "                    .drop_duplicates()\n",
    "\n",
    "display(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting predictions to .csv\n",
    "# CHANGE FILE NAME TO PRESERVE DIFFERENT INSTANCES\n",
    "utils.write_df_to_csv(predictions_df, 'predictions', 'prediction2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
